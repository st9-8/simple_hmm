{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "\n",
    "class HMM(object):\n",
    "    \"\"\"\n",
    "    Here is a simple implementation of a Hidden Markov Models. This implementation assumes that we have:\n",
    "    * A: Transition matrix (probabilities)\n",
    "    * B: Emission matrix (probabilities)\n",
    "    * pi: Initial matrix (probabilities)\n",
    "    * N: Number of Hidden States\n",
    "    * V: Set of observations\n",
    "    * T: Lenght of observation sequence\n",
    "    * O: Observation sequence\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n=None, m=None, states=None, observations=None):\n",
    "        \"\"\"\n",
    "        * param n: size of hidden states set\n",
    "        * param m: size of distincts observations\n",
    "        \"\"\"\n",
    "        self.a = None\n",
    "        self.b = None\n",
    "        self.pi = None\n",
    "        self.params = (self.a, self.b, self.pi)\n",
    "        \n",
    "        if n is not None and m is not None:\n",
    "            self.n = n\n",
    "            self.m = m\n",
    "        else:\n",
    "            raise ValueError('You must provide number of hidden state (n) and number of distincts observations (m)')\n",
    "        \n",
    "        if not states:\n",
    "            raise ValueError('You must provide states list')\n",
    "        if len(states) != self.n:\n",
    "            raise ValueError('Incorrect size of states list')\n",
    "        \n",
    "        # self.states = dict([(v, k) for k, v in list(enumerate(states))])\n",
    "        self.states = dict(enumerate(states))\n",
    "        \n",
    "        if not observations:\n",
    "            raise ValueError('You must provide observations list')\n",
    "        if len(observations) != self.m:\n",
    "            raise ValueError('Incorrect size of observations list')\n",
    "            \n",
    "        self.observations = dict([(v, k) for k, v in list(enumerate(observations))])\n",
    "    \n",
    "    def save_params(self):\n",
    "        \"\"\"\n",
    "        function uses to save model parameters in external file with extension(.ph)\n",
    "        \"\"\"\n",
    "        with open('params.ph', 'wb') as params_file:\n",
    "            pickle.dump(self.params, params_file)\n",
    "    \n",
    "    def set_params_from_file(self, file_path):\n",
    "        try:\n",
    "            with open(file_path, 'rb') as params_file:\n",
    "                params_tmp = pickle.load(params_file)\n",
    "                self.set_params(params_tmp)\n",
    "        except Exception as e:\n",
    "            logging.error(f'Something went wrong: {str(e)}')\n",
    "        \n",
    "    \n",
    "    def set_params(self, a=None, b=None, pi=None):\n",
    "        \"\"\"\n",
    "        function uses to set models parameters\n",
    "        * param a: np.array\n",
    "        * param b: np.array\n",
    "        * param pi: np.array\n",
    "        \n",
    "        If all parameters are None, they will be set randomly\n",
    "        \"\"\"\n",
    "        if a is not None and b is not None and pi is not None:\n",
    "            # Define random parameters\n",
    "            if isinstance(a, np.ndarray):\n",
    "                if a.shape == (self.n, self.n):\n",
    "                    self.a = a\n",
    "                else:\n",
    "                    raise ValueError(f'Error: Please provide A parameter with a shape, expected: ({self.n}, {self.n})')\n",
    "            else:\n",
    "                raise TypeError(f'Error: expected numpy.ndarray as argument')\n",
    "            \n",
    "            if isinstance(b, np.ndarray):\n",
    "                if b.shape == (self.n, self.m):\n",
    "                    self.b = b\n",
    "                else:\n",
    "                    raise ValueError(f'Error: Please provide B parameter with a shape, expected: ({self.n}, {self.m})')\n",
    "            else:\n",
    "                raise Type(f'Expected numpy.ndarray as argument')\n",
    "            \n",
    "            if isinstance(pi, np.ndarray):\n",
    "                if pi.shape == (self.n,):\n",
    "                    self.pi = pi\n",
    "                else:\n",
    "                    raise ValueError(f'Please provide PI parameter with a shape, expected: ({self.n},)')\n",
    "            else:\n",
    "                raise TypeError(f'Expected numpy.ndarray as argument')\n",
    "        else:\n",
    "            # Random initialization\n",
    "            rg = np.random.default_rng()\n",
    "\n",
    "            # Transition matrix\n",
    "            self.a = rg.random((self.n, self.n))\n",
    "            self.a = self.a/self.a.sum(axis=1, keepdims=True)\n",
    "            \n",
    "            # Emission matrix\n",
    "            self.b = rg.random((self.n, self.m))\n",
    "            self.b = self.b/self.b.sum(axis=1, keepdims=True)\n",
    "            \n",
    "            # Transition matrix\n",
    "            self.pi = rg.random(self.n)\n",
    "            self.pi = self.pi/self.pi.sum()\n",
    "        self.params = (self.a, self.b, self.pi)\n",
    "    \n",
    "    def _check_observation(self, observation):\n",
    "        \"\"\"\n",
    "        function use to check validity of observation sequence and state list\n",
    "        \"\"\"\n",
    "        if observation is not None:\n",
    "            valid_obs = all(obs in self.observations for obs in observation)\n",
    "            return valid_obs\n",
    "        return None\n",
    "        \n",
    "    \n",
    "    def _forward_algorithm(self, observation: list):\n",
    "        \"\"\"\n",
    "        implementation of forward algorithm to compute probability P(O|H)\n",
    "        * param observation: Observation sequence for which we want likehood\n",
    "        \"\"\"\n",
    "        if not self._check_observation(observation):\n",
    "            raise ValueError('Your sequence contains symbol which aren\\'t in observation list')\n",
    "            \n",
    "        alphas = np.zeros((self.n, len(observation)))\n",
    "        alphas[:, 0] = self.pi * self.b[:, self.observations[observation[0]]]\n",
    "        for o in range(1, len(observation)):\n",
    "            alphas[:, o] = (alphas[:, o-1] @ self.a) * self.b[:, self.observations[observation[o]]]\n",
    "        \n",
    "        return alphas\n",
    "    \n",
    "    def _backward_algorithm(self, observation: list):\n",
    "        \"\"\"\n",
    "        implementation of backward algorithm to compute probability of P(O|H)\n",
    "        \"\"\"\n",
    "        betas = np.zeros((self.n, len(observation)))\n",
    "        betas[:, -1] = 1\n",
    "        for o in range(len(observation)-2, -1, -1):\n",
    "            betas[:, o] = (betas[:, o+1] @ self.a) * self.b[:, self.observations[observation[o]]]\n",
    "        \n",
    "        return betas\n",
    "        \n",
    "    def likehood(self, observation: list):\n",
    "        \"\"\"\n",
    "        function to return likehood of an observation sequence\n",
    "        * param observation: Observation sequence for which we want likehood\n",
    "        \"\"\"\n",
    "        alphas = self._forward_algorithm(observation)\n",
    "        return alphas[:, -1].sum()\n",
    "        \n",
    "    \n",
    "    def _viterbi_algorithm(self, observation: list):\n",
    "        \"\"\"\n",
    "        function to return the most probable hidden sequence for the given observation\n",
    "        \"\"\"\n",
    "        if not self._check_observation(observation):\n",
    "            raise ValueError('Your sequence contains symbol which aren\\'t in observation list')\n",
    "        # Initial path, viterbi_matrix\n",
    "        best_path = np.zeros(len(observation))\n",
    "        best_path_matrix = np.zeros((self.n, len(observation))) # Which will contains the viterbi value at step i.\n",
    "        viterbi_matrix = np.zeros((self.n, len(observation))) # Which will contains only argmax for each pseudo path\n",
    "        \n",
    "        # Computation\n",
    "        viterbi_matrix[:, 0] = self.pi * self.b[:, self.observations[observation[0]]]\n",
    "        for o in range(1, len(observation)):\n",
    "            for t in range(self.n):\n",
    "                \n",
    "                viterbi_matrix[t, o] = np.max(viterbi_matrix[:, o-1] * self.a[:, t]) * self.b[t, self.observations[observation[o]]]\n",
    "                best_path_matrix[t, o] = np.argmax(viterbi_matrix[:, o-1] * self.a[:, t])\n",
    "        \n",
    "        # Optimal path, proba\n",
    "        best_path_prob = np.max(viterbi_matrix[:, o])     # Get probability at time T(with sequence of lenght T)\n",
    "        best_path[o] = np.argmax(viterbi_matrix[:, o])    # Start reverse to get optimal hidden sequence, by getting the state of the max prob\n",
    "        for obs in range(o-1, -1, -1):\n",
    "            best_path[obs] = best_path_matrix[int(best_path[obs+1]), obs+1]\n",
    "        \n",
    "        return best_path, best_path_prob\n",
    "    \n",
    "    def decoding(self, observation: list):\n",
    "        \"\"\"\n",
    "        function to return the pretty best path for the observation sequence\n",
    "        \"\"\"\n",
    "        best_path, best_prob = self._viterbi_algorithm(observation)\n",
    "        best_path = [self.states[int(i)] for i in best_path]\n",
    "        return ' -> '.join(best_path), f'With: {best_prob}'\n",
    "    \n",
    "    def baum_welch_algorithm(self, observation: list, iterations=10):\n",
    "        \"\"\"\n",
    "        function to learn (A, B) with baum-welch algorithm (EM)\n",
    "        \"\"\"\n",
    "        for iteration in range(iterations):\n",
    "            max_a = self.a\n",
    "            max_b = self.b\n",
    "            xi = np.zeros((self.n, self.n))\n",
    "            xi_over_time = list()\n",
    "            gamma_over_time = list()\n",
    "            gamma = np.zeros((self.n, len(observation)))\n",
    "            alphas = self._forward_algorithm(observation)\n",
    "            betas = self._backward_algorithm(observation)\n",
    "            \n",
    "            # Estimation-Step (E-Step)\n",
    "            for t in range(len(observation)-1): # iterate over all observation\n",
    "                # print('alphas: ', alphas[:, t], 'betas: ', betas[:, t+1])\n",
    "                for i in range(self.n):\n",
    "                    for j in range(self.n):\n",
    "                        numerator = alphas[i, t] * self.a[i, j] * self.b[j, self.observations[observation[t+1]]] * betas[j, t+1]\n",
    "                        xi[i, j] = numerator/alphas[:, -1].sum()\n",
    "                        # print(f'Time {t} --> {xi[i, j]} for {i} to {j}')\n",
    "                    gamma[i, t] = alphas[i, t] * betas[i, t]/alphas[:, -1].sum()\n",
    "                xi_over_time.append(xi)\n",
    "                gamma_over_time.append((observation[t], gamma))\n",
    "                # print(f'Gamma {t}\\n{gamma_over_time}')\n",
    "            \n",
    "            # Maximization-Step (M-Step)\n",
    "            for i in range(self.n):\n",
    "                for j in range(self.n):\n",
    "                    max_a[i, j] = sum([xi[i, j] for xi in xi_over_time])/sum([xi[i, :].sum() for xi in xi_over_time])\n",
    "           \n",
    "\n",
    "            for obs, position in self.observations.items():\n",
    "                for j in range(self.n):\n",
    "\n",
    "                    max_b[j, position] = sum([gamma[1][j, t] for gamma in gamma_over_time if gamma[0] == obs])/sum([gamma[1][j, :].sum() for gamma in gamma_over_time])\n",
    "    \n",
    "            print(f'Iteration {iteration}\\n{max_a}')\n",
    "            # print(f'Iteration {iteration}\\n{max_b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "[[0.36363636 0.63636364]\n",
      " [0.90140845 0.09859155]]\n",
      "Iteration 1\n",
      "[[0.07859744 0.92140256]\n",
      " [0.57713684 0.42286316]]\n",
      "Iteration 2\n",
      "[[0.05411715 0.94588285]\n",
      " [0.47791965 0.52208035]]\n",
      "Iteration 3\n",
      "[[0.03964246 0.96035754]\n",
      " [0.39775783 0.60224217]]\n",
      "Iteration 4\n",
      "[[0.02739269 0.97260731]\n",
      " [0.31064284 0.68935716]]\n",
      "Iteration 5\n",
      "[[0.01762875 0.98237125]\n",
      " [0.22307263 0.77692737]]\n",
      "Iteration 6\n",
      "[[0.01052899 0.98947101]\n",
      " [0.14548645 0.85451355]]\n",
      "Iteration 7\n",
      "[[0.00580298 0.99419702]\n",
      " [0.08541295 0.91458705]]\n",
      "Iteration 8\n",
      "[[0.00289227 0.99710773]\n",
      " [0.0443522  0.9556478 ]]\n",
      "Iteration 9\n",
      "[[0.00123507 0.99876493]\n",
      " [0.01940161 0.98059839]]\n"
     ]
    }
   ],
   "source": [
    "hmm = HMM(2, 2, states=['Sunshine', 'Rain'], observations=['Hot', 'Cold'])\n",
    "hmm.set_params(np.array([[0.2, 0.8], [0.8, 0.2]]), np.array([[0.2, 0.8], [0.65, 0.35]]), np.array([0.3, 0.7]))\n",
    "# t = hmm.likehood(['Hot', 'Hot', 'Cold', 'Hot', 'Cold', 'Cold', 'Hot', 'Hot', 'Hot', 'Cold'])\n",
    "# hmm.decoding(['Hot', 'Hot', 'Cold', 'Hot', 'Hot', 'Cold', 'Cold', 'Cold', 'Cold', 'Hot', 'Hot', 'Hot', 'Cold'])\n",
    "\n",
    "hmm.baum_welch_algorithm(['Hot', 'Hot', 'Cold', 'Hot', 'Hot', 'Cold', 'Cold', 'Cold', 'Cold', 'Hot', 'Hot', 'Hot', 'Cold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
