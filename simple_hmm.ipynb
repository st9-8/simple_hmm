{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "\n",
    "class HMM(object):\n",
    "    \"\"\"\n",
    "    Here is a simple implementation of a Hidden Markov Models. This implementation assumes that we have:\n",
    "    * A: Transition matrix (probabilities)\n",
    "    * B: Emission matrix (probabilities)\n",
    "    * pi: Initial matrix (probabilities)\n",
    "    * N: Number of Hidden States\n",
    "    * V: Set of observations\n",
    "    * T: Lenght of observation sequence\n",
    "    * O: Observation sequence\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n=None, m=None, states=None, observations=None):\n",
    "        \"\"\"\n",
    "        * param n: size of hidden states set\n",
    "        * param m: size of distincts observations\n",
    "        \"\"\"\n",
    "        self.a = None\n",
    "        self.b = None\n",
    "        self.pi = None\n",
    "        self.params = (self.a, self.b, self.pi)\n",
    "        \n",
    "        if n is not None and m is not None:\n",
    "            self.n = n\n",
    "            self.m = m\n",
    "        else:\n",
    "            raise ValueError('You must provide number of hidden state (n) and number of distincts observations (m)')\n",
    "        \n",
    "        if not states:\n",
    "            raise ValueError('You must provide states list')\n",
    "        if len(states) != self.n:\n",
    "            raise ValueError('Incorrect size of states list')\n",
    "        \n",
    "        # self.states = dict([(v, k) for k, v in list(enumerate(states))])\n",
    "        self.states = dict(enumerate(states))\n",
    "        \n",
    "        if not observations:\n",
    "            raise ValueError('You must provide observations list')\n",
    "        if len(observations) != self.m:\n",
    "            raise ValueError('Incorrect size of observations list')\n",
    "            \n",
    "        self.observations = dict([(v, k) for k, v in list(enumerate(observations))])\n",
    "    \n",
    "    def save_params(self):\n",
    "        \"\"\"\n",
    "        function uses to save model parameters in external file with extension(.ph)\n",
    "        \"\"\"\n",
    "        with open('params.ph', 'wb') as params_file:\n",
    "            pickle.dump(self.params, params_file)\n",
    "    \n",
    "    def set_params_from_file(self, file_path):\n",
    "        try:\n",
    "            with open(file_path, 'rb') as params_file:\n",
    "                params_tmp = pickle.load(params_file)\n",
    "                self.set_params(params_tmp)\n",
    "        except Exception as e:\n",
    "            logging.error(f'Something went wrong: {str(e)}')\n",
    "        \n",
    "    \n",
    "    def set_params(self, a=None, b=None, pi=None):\n",
    "        \"\"\"\n",
    "        function uses to set models parameters\n",
    "        * param a: np.array\n",
    "        * param b: np.array\n",
    "        * param pi: np.array\n",
    "        \n",
    "        If all parameters are None, they will be set randomly\n",
    "        \"\"\"\n",
    "        if a is not None and b is not None and pi is not None:\n",
    "            # Define random parameters\n",
    "            if isinstance(a, np.ndarray):\n",
    "                if a.shape == (self.n, self.n):\n",
    "                    self.a = a\n",
    "                else:\n",
    "                    raise ValueError(f'Error: Please provide A parameter with a shape, expected: ({self.n}, {self.n})')\n",
    "            else:\n",
    "                raise TypeError(f'Error: expected numpy.ndarray as argument')\n",
    "            \n",
    "            if isinstance(b, np.ndarray):\n",
    "                if b.shape == (self.n, self.m):\n",
    "                    self.b = b\n",
    "                else:\n",
    "                    raise ValueError(f'Error: Please provide B parameter with a shape, expected: ({self.n}, {self.m})')\n",
    "            else:\n",
    "                raise Type(f'Expected numpy.ndarray as argument')\n",
    "            \n",
    "            if isinstance(pi, np.ndarray):\n",
    "                if pi.shape == (self.n,):\n",
    "                    self.pi = pi\n",
    "                else:\n",
    "                    raise ValueError(f'Please provide PI parameter with a shape, expected: ({self.n},)')\n",
    "            else:\n",
    "                raise TypeError(f'Expected numpy.ndarray as argument')\n",
    "        else:\n",
    "            # Random initialization\n",
    "            rg = np.random.default_rng()\n",
    "\n",
    "            # Transition matrix\n",
    "            self.a = rg.random((self.n, self.n))\n",
    "            self.a = self.a/self.a.sum(axis=1, keepdims=True)\n",
    "            \n",
    "            # Emission matrix\n",
    "            self.b = rg.random((self.n, self.m))\n",
    "            self.b = self.b/self.b.sum(axis=1, keepdims=True)\n",
    "            \n",
    "            # Transition matrix\n",
    "            self.pi = rg.random(self.n)\n",
    "            self.pi = self.pi/self.pi.sum()\n",
    "        self.params = (self.a, self.b, self.pi)\n",
    "    \n",
    "    def _check_observation(self, observation):\n",
    "        \"\"\"\n",
    "        function use to check validity of observation sequence and state list\n",
    "        \"\"\"\n",
    "        if observation is not None:\n",
    "            valid_obs = all(obs in self.observations for obs in observation)\n",
    "            return valid_obs\n",
    "        return None\n",
    "        \n",
    "    \n",
    "    def _forward_algorithm(self, observation: list):\n",
    "        \"\"\"\n",
    "        implementation of forward algorithm to compute probability P(O|H)\n",
    "        * param observation: Observation sequence for which we want likehood\n",
    "        \"\"\"\n",
    "        if not self._check_observation(observation):\n",
    "            raise ValueError('Your sequence contains symbol which aren\\'t in observation list')\n",
    "            \n",
    "        alphas = np.zeros((self.n, len(observation)))\n",
    "        alphas[:, 0] = self.pi * self.b[:, self.observations[observation[0]]]\n",
    "        for o in range(1, len(observation)):\n",
    "            alphas[:, o] = (alphas[:, o-1] @ self.a) * self.b[:, self.observations[observation[o]]]\n",
    "        \n",
    "        return alphas\n",
    "    \n",
    "    def _backward_algorithm(self, observation: list):\n",
    "        \"\"\"\n",
    "        implementation of backward algorithm to compute probability of P(O|H)\n",
    "        \"\"\"\n",
    "        betas = np.zeros((self.n, len(observation)))\n",
    "        betas[:, -1] = 1\n",
    "        for o in range(len(observation)-2, -1, -1):\n",
    "            betas[:, o] = (betas[:, o+1] @ self.a) * self.b[:, self.observations[observation[o]]]\n",
    "        \n",
    "        return betas\n",
    "        \n",
    "    def likehood(self, observation: list):\n",
    "        \"\"\"\n",
    "        function to return likehood of an observation sequence\n",
    "        * param observation: Observation sequence for which we want likehood\n",
    "        \"\"\"\n",
    "        alphas = self._forward_algorithm(observation)\n",
    "        return alphas[:, -1].sum()\n",
    "        \n",
    "    \n",
    "    def _viterbi_algorithm(self, observation: list):\n",
    "        \"\"\"\n",
    "        function to return the most probable hidden sequence for the given observation\n",
    "        \"\"\"\n",
    "        if not self._check_observation(observation):\n",
    "            raise ValueError('Your sequence contains symbol which aren\\'t in observation list')\n",
    "        # Initial path, viterbi_matrix\n",
    "        best_path = np.zeros(len(observation))\n",
    "        best_path_matrix = np.zeros((self.n, len(observation))) # Which will contains the viterbi value at step i.\n",
    "        viterbi_matrix = np.zeros((self.n, len(observation))) # Which will contains only argmax for each pseudo path\n",
    "        \n",
    "        # Computation\n",
    "        viterbi_matrix[:, 0] = self.pi * self.b[:, self.observations[observation[0]]]\n",
    "        for o in range(1, len(observation)):\n",
    "            for t in range(self.n):\n",
    "                \n",
    "                viterbi_matrix[t, o] = np.max(viterbi_matrix[:, o-1] * self.a[:, t]) * self.b[t, self.observations[observation[o]]]\n",
    "                best_path_matrix[t, o] = np.argmax(viterbi_matrix[:, o-1] * self.a[:, t])\n",
    "        \n",
    "        # Optimal path, proba\n",
    "        best_path_prob = np.max(viterbi_matrix[:, o])     # Get probability at time T(with sequence of lenght T)\n",
    "        best_path[o] = np.argmax(viterbi_matrix[:, o])    # Start reverse to get optimal hidden sequence, by getting the state of the max prob\n",
    "        for obs in range(o-1, -1, -1):\n",
    "            best_path[obs] = best_path_matrix[int(best_path[obs+1]), obs+1]\n",
    "        \n",
    "        return best_path, best_path_prob\n",
    "    \n",
    "    def decoding(self, observation: list):\n",
    "        \"\"\"\n",
    "        function to return the pretty best path for the observation sequence\n",
    "        \"\"\"\n",
    "        best_path, best_prob = self._viterbi_algorithm(observation)\n",
    "        best_path = [self.states[int(i)] for i in best_path]\n",
    "        return ' -> '.join(best_path), f'With: {best_prob}'\n",
    "    \n",
    "    def baum_welch_algorithm(self, observation: list, iterations=4):\n",
    "        \"\"\"\n",
    "        function to learn (A, B) with baum-welch algorithm (EM)\n",
    "        \"\"\"\n",
    "        print('BEFORE TRAINING')\n",
    "        print(f'A: {self.a}')\n",
    "        print(f'B: {self.b}')\n",
    "        \n",
    "        for iteration in range(iterations):\n",
    "            max_a = self.a\n",
    "            max_b = self.b\n",
    "            xi = np.zeros((self.n, self.n))\n",
    "            xi_over_time = list()\n",
    "            gamma_over_time = list()\n",
    "            gamma = np.zeros((self.n, len(observation)))\n",
    "            alphas = self._forward_algorithm(observation)\n",
    "            betas = self._backward_algorithm(observation)\n",
    "            \n",
    "            # Estimation-Step (E-Step)\n",
    "            for t in range(len(observation)-1): # iterate over all observation\n",
    "                # print('alphas: ', alphas[:, t], 'betas: ', betas[:, t+1])\n",
    "                for i in range(self.n):\n",
    "                    for j in range(self.n):\n",
    "                        numerator = alphas[i, t] * self.a[i, j] * self.b[j, self.observations[observation[t+1]]] * betas[j, t+1]\n",
    "                        xi[i, j] = numerator/alphas[:, -1].sum()\n",
    "                        # print(f'Time {t} --> {xi[i, j]} for {i} to {j}')\n",
    "                \n",
    "                xi_over_time.append(xi)\n",
    "                # gamma_over_time.append((observation[t], gamma))\n",
    "                # print(f'Gamma {t}\\n{gamma_over_time}')\n",
    "            gamma = (alphas * betas)/self.likehood(observation)\n",
    "            # Maximization-Step (M-Step)\n",
    "            for i in range(self.n):\n",
    "                for j in range(self.n):\n",
    "                    max_a[i, j] = sum([xi[i, j] for xi in xi_over_time])/sum([xi[i, :].sum() for xi in xi_over_time])\n",
    "           \n",
    "            self.a = max_a\n",
    "            for obs, position in self.observations.items():\n",
    "                for j in range(self.n):\n",
    "\n",
    "                    max_b[j, position] = sum([gamma[j, seq] for seq in range(len(observation)) if observation[seq] == obs])/gamma[j, :].sum()\n",
    "            self.b = max_b\n",
    "            # print(f'Iteration {iteration}\\n{max_a}')\n",
    "            # print(f'Iteration {iteration}\\n{max_b}')\n",
    "        print('AFTER TRAINING')\n",
    "        print(f'A: {self.a}')\n",
    "        print(f'B: {self.b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE TRAINING\n",
      "A: [[0.63278215 0.36721785]\n",
      " [0.49441875 0.50558125]]\n",
      "B: [[0.52115629 0.47884371]\n",
      " [0.55161521 0.44838479]]\n",
      "AFTER TRAINING\n",
      "A: [[0.95742958 0.04257042]\n",
      " [0.92734448 0.07265552]]\n",
      "B: [[0.760864   0.239136  ]\n",
      " [0.97608944 0.02391056]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Rain -> Sunshine -> Sunshine -> Sunshine -> Sunshine -> Sunshine -> Sunshine -> Sunshine',\n",
       " 'With: 0.09933748449543231')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm = HMM(2, 2, states=['Sunshine', 'Rain'], observations=['Hot', 'Cold'])\n",
    "hmm.set_params()\n",
    "# t = hmm.likehood(['Hot', 'Hot', 'Cold', 'Hot', 'Cold', 'Cold', 'Hot', 'Hot', 'Hot', 'Cold'])\n",
    "# hmm.decoding(['Hot', 'Hot', 'Cold', 'Hot', 'Hot', 'Cold', 'Cold', 'Cold', 'Cold', 'Hot', 'Hot', 'Hot', 'Cold'])\n",
    "\n",
    "hmm.baum_welch_algorithm(['Hot', 'Cold', 'Hot', 'Cold', 'Hot', 'Hot', 'Hot', 'Cold'])\n",
    "hmm.decoding(['Hot', 'Hot', 'Hot', 'Hot', 'Hot', 'Hot', 'Hot', 'Hot'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
